{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import platform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import read_atlas_layer_points as rlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_index_range= [1]\n",
    "number_of_atlas = 31;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder, main_folder, manual_seg_filename, atlas_filenames = None, None, None, None\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    input_folder = 'C:/D/dev/data/20171204_cirrus_manual'\n",
    "    main_folder = 'C:/D/dev/data/20171205_cirrus_manual_results'\n",
    "    manual_seg_filename = 'C:/D/dev/Xnorm/experiments/oct/20171204_manual_segmentation/filenames.txt'\n",
    "    atlas_filenames = 'C:/D/dev/Xnorm/experiments/oct/20170830_large_healthy_data_proc/cirrus_od_altas_folder_linux_iacl.txt'\n",
    "elif platform.system() == 'Linux':\n",
    "    input_folder = '/iacl/pg17/ja/data/20171204_cirrus_manual/'\n",
    "    main_folder = '/iacl/pg17/ja/data/20171205_cirrus_manual_results/'\n",
    "    manual_seg_filename = '/home/ja/dev/Xnorm/experiments/oct/20171204_manual_segmentation/filenames.txt'\n",
    "    atlas_filenames = '/home/ja/dev/Xnorm/experiments/oct/20170830_large_healthy_data_proc/cirrus_od_altas_folder_linux_iacl.txt'\n",
    "\n",
    "pids, image_prefixes = rlp.read_manual_segmentation_oct_files(manual_seg_filename)\n",
    "atlas_folders, atlas_subfolders = rlp.read_atlas_images_files(atlas_filenames)\n",
    "\n",
    "#print('PID: {}\\nImagePrefixes:{}'.format(pids, image_prefixes))\n",
    "#print('Atlas folders:{}\\nAtlas subfolders:{}'.format(atlas_folders, atlas_subfolders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 31 atlases\n"
     ]
    }
   ],
   "source": [
    "shuffle=False\n",
    "used_pids = []\n",
    "for idx in pid_index_range: used_pids.append(pids[idx])    \n",
    "\n",
    "deformed_layer_shuffle_points4pids = rlp.get_layer_points_for_pids(used_pids, \n",
    "                                    atlas_subfolders, shuffle, main_folder, number_of_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1092977057, P1092977057_Macular Cube 512x128_2-15-2012_16-13-29_OS_sn10264_cube_z\n",
      "folder /iacl/pg17/ja/data/20171204_cirrus_manual/\n",
      "file/iacl/pg17/ja/data/20171204_cirrus_manual/P1092977057_Macular Cube 512x128_2-15-2012_16-13-29_OS_sn10264_cube_z_flatten_result.csv\n"
     ]
    }
   ],
   "source": [
    "print('{}, {}'.format(pids[idx], image_prefixes[pid_index_range[0]]))\n",
    "fname = '%s_flatten_result.csv' % image_prefixes[pid_index_range[0]]\n",
    "filename = os.path.join(input_folder, fname)\n",
    "print('folder {}\\nfile{}'.format(input_folder, filename))\n",
    "reference_labeled_points = rlp.read_layer_points(filename, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.790254 5.9319   5.9944  ]\n",
      " [0.791324 5.9436   5.9944  ]\n",
      " [0.792297 5.9553   5.9944  ]\n",
      " [0.793071 5.967    5.9944  ]\n",
      " [0.793594 5.9787   5.9944  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.708042, 6.13453 , 5.75754 ],\n",
       "       [0.707691, 6.14623 , 5.75755 ],\n",
       "       [0.707274, 6.15794 , 5.75756 ],\n",
       "       [0.706949, 6.16964 , 5.75756 ],\n",
       "       [0.706774, 6.18134 , 5.75757 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reference_labeled_points['1'][65536-5:, :])\n",
    "start_npnt = 65536*30\n",
    "deformed_layer_shuffle_points4pids['P1092977057']['1'][start_npnt-5:start_npnt, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, data_points, reference_labeled_points, label, val_frac=0.25,\\\n",
    "                 do_normalize=True, num_pnt_per_boundary = 512*128):\n",
    "        \n",
    "        self.input_dim = num_pnt_per_boundary*2\n",
    "        self.output_dim = num_pnt_per_boundary\n",
    "        \n",
    "        train_data = data_points[label]\n",
    "        test_data = reference_labeled_points[label]\n",
    "        \n",
    "        self.scaler = MinMaxScaler().fit(np.concatenate((train_data, test_data)))\n",
    "        #print('Scaler mean: ', std_scaler.mean_, ' scale: ', std_scaler.scale_)\n",
    "        train_data_scaled = self.scaler.fit_transform(train_data)\n",
    "        test_data_scaled = self.scaler.fit_transform(test_data)\n",
    "        #print('Train data size ', train_data_scaled.shape)\n",
    "        #print('Original test data: \\n', test_data[10:12, :])\n",
    "        #print('\\nScaled test data: \\n', test_data_scaled[10:12, :])\n",
    "        #print('\\nUnscaled test data: \\n', self.scaler.inverse_transform(test_data_scaled[10:12, :]))\n",
    "        #y_scaler.inverse_transform(predicted)\n",
    "        \n",
    "        print('Train yz before reshape \\n', train_data_scaled[:4, 1:])\n",
    "        self.train_yz = train_data_scaled[:, 1:].reshape((-1, self.input_dim))\n",
    "        self.train_x = train_data_scaled[:,0].reshape((-1, self.output_dim))\n",
    "        print('Train yz after reshape \\n', self.train_yz[0, :8])\n",
    "        print('Train yz shape ', self.train_yz.shape, ' train x shape ', self.train_x.shape)\n",
    "        \n",
    "        self.num_ref_points = test_data_scaled.shape[0]\n",
    "        if val_frac > 1e-8:\n",
    "            split_idx = int(number_of_reference_points*(1 - val_frac))\n",
    "\n",
    "            self.test_yz, self.valid_yz = test_data_scaled[:split_idx, 1:].reshape((-1, 1)),\\\n",
    "                                          test_data_scaled[split_idx:, 1:].reshape((-1, 1))\n",
    "            self.test_x, self.valid_x = test_data_scaled[:split_idx, 0], \\\n",
    "                                        test_data_scaled[split_idx:, 0]\n",
    "        else:\n",
    "            self.test_yz, self.valid_yz = None, test_data_scaled[:, 1:].reshape((1,- 1))\n",
    "            self.test_x, self.valid_x = None, test_data_scaled[:, 0].reshape((1,- 1))        \n",
    "            \n",
    "        print('Validation yz shape ', self.valid_yz.shape, ' validation x shape ', self.valid_x.shape)\n",
    "        \n",
    "    def batches(self, batch_size):\n",
    "        n_batches = len(self.train_x)//batch_size\n",
    "        for ii in range(0, len(self.train_x), batch_size):\n",
    "            yz = self.train_yz[ii:ii+batch_size, :]\n",
    "            x = self.train_x[ii:ii+batch_size]\n",
    "            \n",
    "            yield yz, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train yz before reshape \n",
      " [[2.3064176e-02 0.0000000e+00]\n",
      " [2.4927836e-02 3.0547380e-07]\n",
      " [2.6791334e-02 7.5995922e-07]\n",
      " [2.8654834e-02 1.0728836e-06]]\n",
      "Train yz after reshape \n",
      " [2.3064176e-02 0.0000000e+00 2.4927836e-02 3.0547380e-07 2.6791334e-02\n",
      " 7.5995922e-07 2.8654834e-02 1.0728836e-06]\n",
      "Train yz shape  (31, 131072)  train x shape  (31, 65536)\n",
      "Validation yz shape  (1, 131072)  validation x shape  (1, 65536)\n",
      "<class 'numpy.ndarray'>\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "dataset = Dataset(deformed_layer_shuffle_points4pids[used_pids[0]],\n",
    "                  reference_labeled_points, '1', val_frac=0.0, do_normalize=True)\n",
    "print(type(dataset.train_x))\n",
    "print(dataset.scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7979355  0.79459834 0.7914548  ... 0.5132446  0.51263237 0.5125148 ]\n",
      "[0.64644575 0.64461374 0.64223075 ... 0.46842074 0.4745648  0.47907043]\n",
      "[0.85466456 0.84704566 0.83781457 ... 0.49079204 0.4976809  0.5044167 ]\n",
      "[[0.7724314  0.76861286 0.7657361  ... 0.90901375 0.9144969  0.9182024 ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.train_x[0])\n",
    "print(dataset.train_x[1])\n",
    "print(dataset.train_x[2])\n",
    "print(dataset.valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sknn.mlp import Regressor, Layer, Native\n",
    "from lasagne import layers as lasagne, nonlinearities as nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = 131072, 65536\n",
    "batch_size = 1\n",
    "n_iter=500\n",
    "loss_type='mse'\n",
    "#learning_rates = [1e2]#[1e9, 1e8, 1e7, 1e6, 1e5]#[10, 1, 0.1, 0.01, 0.001, 1e-4, 1e-5]\n",
    "learning_rate = 10\n",
    "hidden_units_list = [16, 32, 64, 128, 256, 512, 1024]\n",
    "#hidden_units = [16]\n",
    "dropouts = []\n",
    "normalizes = []\n",
    "activation=\"Tanh\"\n",
    "valid_set = (dataset.valid_yz, dataset.valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'256_64'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "all_hidden_units = []\n",
    "\n",
    "#for hunit in hidden_units_list:\n",
    "#    all_hidden_units.append([hunit])\n",
    "\n",
    "all_hidden_units.append([1024])\n",
    "for i in range(4):\n",
    "    for j in range(i+1, len(hidden_units_list)-3+i, 1):\n",
    "        all_hidden_units.append([hidden_units_list[j], hidden_units_list[i]])\n",
    "\n",
    "all_hidden_units    \n",
    "\n",
    "#l = list(permutations(hidden0_units))\n",
    "#print(l)\n",
    "str(all_hidden_units[8])\n",
    "'_'.join([str(n) for n in all_hidden_units[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layers(hidden_units, dropouts=None, normalizes=None, activation=\"Tanh\", output_dim=65536):\n",
    "    layers = []\n",
    "    for idx, hu in enumerate(hidden_units):\n",
    "        if dropouts and normalizes and dropouts[idx] and normalizes[idx]:\n",
    "            layers.append(Layer(activation, units=hu, dropout=dropouts[idx] ,\n",
    "                                normalize=normalizes[idx]))\n",
    "        elif dropouts and dropouts[idx]:\n",
    "            layers.append(Layer(activation, units=hu, dropout=dropouts[idx] ))\n",
    "        elif normalizes and normalizes[idx]:\n",
    "            layers.append(Layer(activation, units=hu, normalize=normalizes[idx]))\n",
    "        else:\n",
    "            layers.append(Layer(activation, units=hu))\n",
    "    layers.append(Layer(\"Linear\", units= output_dim))     \n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_log_error(filename, errors):\n",
    "    with open(filename, \"w\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        for error in errors:\n",
    "            writer.writerow(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(dataset, X, y, prediction):\n",
    "    X= X.reshape(-1, 2)\n",
    "    y = y.reshape(-1, 1)\n",
    "    prediction = prediction.reshape(-1,1)\n",
    "    #print('X ', X.shape, ' y ', y.shape, ' pred ', prediction.shape)\n",
    "    reference = np.hstack((y, X))\n",
    "    prediction = np.hstack((prediction, X))\n",
    "    #print('Before Reference \\n', reference, '\\nPrediction\\n', prediction)\n",
    "    reference = dataset.scaler.inverse_transform(reference)\n",
    "    prediction = dataset.scaler.inverse_transform(prediction)\n",
    "    #print('After Reference \\n', reference, '\\nPrediction\\n', prediction)\n",
    "    differences = np.abs(prediction[:, 0] - reference[:, 0])\n",
    "    mad = np.mean(differences)\n",
    "    return mad, max(differences), min(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing neural network with 2 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m1024\u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 4.336e-02\u001b[0m            \u001b[0;32m 2.186e-02\u001b[0m        135.6s                                     \n",
      "    2         \u001b[0;94m 7.905e-03\u001b[0m             2.200e-02        118.8s                                                \n",
      "    3         \u001b[0;94m 7.843e-03\u001b[0m             2.658e-02        119.1s                                                \n",
      "    4          7.993e-03             2.888e-02        117.3s                                                           \n",
      "    5         \u001b[0;94m 7.776e-03\u001b[0m            \u001b[0;32m 2.004e-02\u001b[0m        116.0s                                     \n",
      "    6         \u001b[0;94m 7.707e-03\u001b[0m             2.240e-02        117.9s                                                \n",
      "    7          7.725e-03             2.098e-02        117.3s                                                           \n",
      "    8         \u001b[0;94m 7.682e-03\u001b[0m            \u001b[0;32m 1.968e-02\u001b[0m        112.9s                                     \n",
      "    9         \u001b[0;94m 7.223e-03\u001b[0m             2.399e-02        111.3s                                                \n",
      "   10          8.025e-03             2.163e-02        112.1s                                                           \n",
      "   11          7.308e-03             2.852e-02        116.2s                                                           \n",
      "   12          7.429e-03             2.308e-02        116.2s                                                           \n",
      "   13          7.765e-03             2.336e-02        116.0s                                                           \n",
      "   14          7.741e-03             2.138e-02        118.3s                                                           \n",
      "   15          7.345e-03             2.723e-02        116.4s                                                           \n",
      "   16          8.040e-03             2.807e-02        116.3s                                                           \n",
      "   17          7.845e-03             2.801e-02        117.3s                                                           \n",
      "   18          7.818e-03             2.604e-02        116.5s                                                           \n",
      "\n",
      "Early termination condition fired at 18 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m32  \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m16  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 2.615e-01\u001b[0m            \u001b[0;32m 1.893e-01\u001b[0m          3.5s                                     \n",
      "    2         \u001b[0;94m 1.927e-01\u001b[0m            \u001b[0;32m 1.373e-01\u001b[0m          3.3s                                     \n",
      "    3         \u001b[0;94m 1.413e-01\u001b[0m            \u001b[0;32m 1.006e-01\u001b[0m          3.3s                                     \n",
      "    4         \u001b[0;94m 1.041e-01\u001b[0m            \u001b[0;32m 7.483e-02\u001b[0m          3.7s                                     \n",
      "    5         \u001b[0;94m 7.715e-02\u001b[0m            \u001b[0;32m 5.685e-02\u001b[0m          3.0s                                     \n",
      "    6         \u001b[0;94m 5.761e-02\u001b[0m            \u001b[0;32m 4.443e-02\u001b[0m          3.4s                                     \n",
      "    7         \u001b[0;94m 4.346e-02\u001b[0m            \u001b[0;32m 3.596e-02\u001b[0m          3.3s                                     \n",
      "    8         \u001b[0;94m 3.323e-02\u001b[0m            \u001b[0;32m 3.027e-02\u001b[0m          3.3s                                     \n",
      "    9         \u001b[0;94m 2.580e-02\u001b[0m            \u001b[0;32m 2.650e-02\u001b[0m          3.3s                                     \n",
      "   10         \u001b[0;94m 2.042e-02\u001b[0m            \u001b[0;32m 2.409e-02\u001b[0m          3.5s                                     \n",
      "   11         \u001b[0;94m 1.652e-02\u001b[0m            \u001b[0;32m 2.261e-02\u001b[0m          3.2s                                     \n",
      "   12         \u001b[0;94m 1.371e-02\u001b[0m            \u001b[0;32m 2.181e-02\u001b[0m          3.1s                                     \n",
      "   13         \u001b[0;94m 1.168e-02\u001b[0m            \u001b[0;32m 2.140e-02\u001b[0m          3.4s                                     \n",
      "   14         \u001b[0;94m 1.020e-02\u001b[0m            \u001b[0;32m 2.126e-02\u001b[0m          3.5s                                     \n",
      "   15         \u001b[0;94m 9.130e-03\u001b[0m             2.129e-02          3.1s                                                \n",
      "   16         \u001b[0;94m 8.356e-03\u001b[0m             2.146e-02          3.1s                                                \n",
      "   17         \u001b[0;94m 7.799e-03\u001b[0m             2.166e-02          3.1s                                                \n",
      "   18         \u001b[0;94m 7.395e-03\u001b[0m             2.191e-02          3.2s                                                \n",
      "   19         \u001b[0;94m 7.100e-03\u001b[0m             2.216e-02          3.1s                                                \n",
      "   20         \u001b[0;94m 6.886e-03\u001b[0m             2.242e-02          3.1s                                                \n",
      "   21         \u001b[0;94m 6.731e-03\u001b[0m             2.265e-02          3.0s                                                \n",
      "   22         \u001b[0;94m 6.619e-03\u001b[0m             2.286e-02          3.2s                                                \n",
      "   23         \u001b[0;94m 6.539e-03\u001b[0m             2.306e-02          3.1s                                                \n",
      "   24         \u001b[0;94m 6.480e-03\u001b[0m             2.323e-02          3.1s                                                \n",
      "\n",
      "Early termination condition fired at 24 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m64  \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m16  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 2.582e-01\u001b[0m            \u001b[0;32m 1.860e-01\u001b[0m          5.5s                                     \n",
      "    2         \u001b[0;94m 1.894e-01\u001b[0m            \u001b[0;32m 1.350e-01\u001b[0m          5.6s                                     \n",
      "    3         \u001b[0;94m 1.389e-01\u001b[0m            \u001b[0;32m 9.895e-02\u001b[0m          5.3s                                     \n",
      "    4         \u001b[0;94m 1.024e-01\u001b[0m            \u001b[0;32m 7.366e-02\u001b[0m          6.0s                                     \n",
      "    5         \u001b[0;94m 7.586e-02\u001b[0m            \u001b[0;32m 5.601e-02\u001b[0m          5.7s                                     \n",
      "    6         \u001b[0;94m 5.669e-02\u001b[0m            \u001b[0;32m 4.386e-02\u001b[0m          5.6s                                     \n",
      "    7         \u001b[0;94m 4.280e-02\u001b[0m            \u001b[0;32m 3.558e-02\u001b[0m          5.3s                                     \n",
      "    8         \u001b[0;94m 3.273e-02\u001b[0m            \u001b[0;32m 3.003e-02\u001b[0m          5.6s                                     \n",
      "    9         \u001b[0;94m 2.546e-02\u001b[0m            \u001b[0;32m 2.638e-02\u001b[0m          5.9s                                     \n",
      "   10         \u001b[0;94m 2.018e-02\u001b[0m            \u001b[0;32m 2.402e-02\u001b[0m          5.5s                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11         \u001b[0;94m 1.636e-02\u001b[0m            \u001b[0;32m 2.261e-02\u001b[0m          5.6s                                     \n",
      "   12         \u001b[0;94m 1.360e-02\u001b[0m            \u001b[0;32m 2.181e-02\u001b[0m          5.7s                                     \n",
      "   13         \u001b[0;94m 1.160e-02\u001b[0m            \u001b[0;32m 2.142e-02\u001b[0m          5.8s                                     \n",
      "   14         \u001b[0;94m 1.015e-02\u001b[0m            \u001b[0;32m 2.128e-02\u001b[0m          5.4s                                     \n",
      "   15         \u001b[0;94m 9.091e-03\u001b[0m             2.132e-02          5.8s                                                \n",
      "   16         \u001b[0;94m 8.328e-03\u001b[0m             2.148e-02          5.5s                                                \n",
      "   17         \u001b[0;94m 7.777e-03\u001b[0m             2.171e-02          5.5s                                                \n",
      "   18         \u001b[0;94m 7.378e-03\u001b[0m             2.196e-02          5.7s                                                \n",
      "   19         \u001b[0;94m 7.089e-03\u001b[0m             2.222e-02          5.6s                                                \n",
      "   20         \u001b[0;94m 6.877e-03\u001b[0m             2.245e-02          5.3s                                                \n",
      "   21         \u001b[0;94m 6.723e-03\u001b[0m             2.268e-02          5.4s                                                \n",
      "   22         \u001b[0;94m 6.614e-03\u001b[0m             2.289e-02          5.4s                                                \n",
      "   23         \u001b[0;94m 6.534e-03\u001b[0m             2.309e-02          6.2s                                                \n",
      "   24         \u001b[0;94m 6.476e-03\u001b[0m             2.326e-02          5.3s                                                \n",
      "\n",
      "Early termination condition fired at 24 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m128 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m16  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 2.567e-01\u001b[0m            \u001b[0;32m 1.847e-01\u001b[0m         10.2s                                     \n",
      "    2         \u001b[0;94m 1.880e-01\u001b[0m            \u001b[0;32m 1.340e-01\u001b[0m         10.7s                                     \n",
      "    3         \u001b[0;94m 1.379e-01\u001b[0m            \u001b[0;32m 9.833e-02\u001b[0m          9.9s                                     \n",
      "    4         \u001b[0;94m 1.016e-01\u001b[0m            \u001b[0;32m 7.324e-02\u001b[0m         10.5s                                     \n",
      "    5         \u001b[0;94m 7.536e-02\u001b[0m            \u001b[0;32m 5.576e-02\u001b[0m         10.3s                                     \n",
      "    6         \u001b[0;94m 5.634e-02\u001b[0m            \u001b[0;32m 4.374e-02\u001b[0m         10.2s                                     \n",
      "    7         \u001b[0;94m 4.255e-02\u001b[0m            \u001b[0;32m 3.548e-02\u001b[0m         10.4s                                     \n",
      "    8         \u001b[0;94m 3.254e-02\u001b[0m            \u001b[0;32m 2.994e-02\u001b[0m         10.1s                                     \n",
      "    9         \u001b[0;94m 2.531e-02\u001b[0m            \u001b[0;32m 2.631e-02\u001b[0m         10.2s                                     \n",
      "   10         \u001b[0;94m 2.007e-02\u001b[0m            \u001b[0;32m 2.400e-02\u001b[0m         10.7s                                     \n",
      "   11         \u001b[0;94m 1.628e-02\u001b[0m            \u001b[0;32m 2.258e-02\u001b[0m          9.8s                                     \n",
      "   12         \u001b[0;94m 1.354e-02\u001b[0m            \u001b[0;32m 2.178e-02\u001b[0m         10.1s                                     \n",
      "   13         \u001b[0;94m 1.156e-02\u001b[0m            \u001b[0;32m 2.140e-02\u001b[0m         10.0s                                     \n",
      "   14         \u001b[0;94m 1.012e-02\u001b[0m            \u001b[0;32m 2.129e-02\u001b[0m         10.7s                                     \n",
      "   15         \u001b[0;94m 9.071e-03\u001b[0m             2.133e-02         10.8s                                                \n",
      "   16         \u001b[0;94m 8.311e-03\u001b[0m             2.148e-02         10.3s                                                \n",
      "   17         \u001b[0;94m 7.761e-03\u001b[0m             2.170e-02         10.0s                                                \n",
      "   18         \u001b[0;94m 7.365e-03\u001b[0m             2.195e-02         10.2s                                                \n",
      "   19         \u001b[0;94m 7.075e-03\u001b[0m             2.219e-02         10.2s                                                \n",
      "   20         \u001b[0;94m 6.867e-03\u001b[0m             2.243e-02         10.4s                                                \n",
      "   21         \u001b[0;94m 6.716e-03\u001b[0m             2.265e-02         10.2s                                                \n",
      "   22         \u001b[0;94m 6.607e-03\u001b[0m             2.287e-02         10.4s                                                \n",
      "   23         \u001b[0;94m 6.529e-03\u001b[0m             2.306e-02         10.1s                                                \n",
      "   24         \u001b[0;94m 6.472e-03\u001b[0m             2.323e-02         10.7s                                                \n",
      "\n",
      "Early termination condition fired at 24 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m64  \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m32  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 2.389e-01\u001b[0m            \u001b[0;32m 1.477e-01\u001b[0m          6.0s                                     \n",
      "    2         \u001b[0;94m 1.331e-01\u001b[0m            \u001b[0;32m 8.125e-02\u001b[0m          6.0s                                     \n",
      "    3         \u001b[0;94m 7.408e-02\u001b[0m            \u001b[0;32m 4.822e-02\u001b[0m          6.2s                                     \n",
      "    4         \u001b[0;94m 4.252e-02\u001b[0m            \u001b[0;32m 3.234e-02\u001b[0m          6.0s                                     \n",
      "    5         \u001b[0;94m 2.567e-02\u001b[0m            \u001b[0;32m 2.518e-02\u001b[0m          6.0s                                     \n",
      "    6         \u001b[0;94m 1.668e-02\u001b[0m            \u001b[0;32m 2.223e-02\u001b[0m          6.2s                                     \n",
      "    7         \u001b[0;94m 1.187e-02\u001b[0m            \u001b[0;32m 2.141e-02\u001b[0m          6.0s                                     \n",
      "    8         \u001b[0;94m 9.318e-03\u001b[0m             2.150e-02          6.1s                                                \n",
      "    9         \u001b[0;94m 7.948e-03\u001b[0m             2.186e-02          6.3s                                                \n",
      "   10         \u001b[0;94m 7.206e-03\u001b[0m             2.236e-02          6.2s                                                \n",
      "   11         \u001b[0;94m 6.811e-03\u001b[0m             2.281e-02          5.9s                                                \n",
      "   12         \u001b[0;94m 6.601e-03\u001b[0m             2.321e-02          6.3s                                                \n",
      "   13         \u001b[0;94m 6.487e-03\u001b[0m             2.349e-02          6.0s                                                \n",
      "   14         \u001b[0;94m 6.424e-03\u001b[0m             2.374e-02          5.9s                                                \n",
      "   15         \u001b[0;94m 6.392e-03\u001b[0m             2.389e-02          5.9s                                                \n",
      "   16         \u001b[0;94m 6.374e-03\u001b[0m             2.401e-02          6.0s                                                \n",
      "   17         \u001b[0;94m 6.363e-03\u001b[0m             2.405e-02          5.9s                                                \n",
      "\n",
      "Early termination condition fired at 17 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m128 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m32  \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 2.308e-01\u001b[0m            \u001b[0;32m 1.405e-01\u001b[0m         10.8s                                     \n",
      "    2         \u001b[0;94m 1.269e-01\u001b[0m            \u001b[0;32m 7.771e-02\u001b[0m         10.6s                                     \n",
      "    3         \u001b[0;94m 7.085e-02\u001b[0m            \u001b[0;32m 4.662e-02\u001b[0m         10.4s                                     \n",
      "    4         \u001b[0;94m 4.083e-02\u001b[0m            \u001b[0;32m 3.150e-02\u001b[0m         10.8s                                     \n",
      "    5         \u001b[0;94m 2.476e-02\u001b[0m            \u001b[0;32m 2.473e-02\u001b[0m         11.2s                                     \n",
      "    6         \u001b[0;94m 1.620e-02\u001b[0m            \u001b[0;32m 2.213e-02\u001b[0m         10.8s                                     \n",
      "    7         \u001b[0;94m 1.161e-02\u001b[0m            \u001b[0;32m 2.133e-02\u001b[0m         10.8s                                     \n",
      "    8         \u001b[0;94m 9.150e-03\u001b[0m             2.144e-02         10.6s                                                \n",
      "    9         \u001b[0;94m 7.838e-03\u001b[0m             2.190e-02         10.6s                                                \n",
      "   10         \u001b[0;94m 7.152e-03\u001b[0m             2.237e-02         10.5s                                                \n",
      "   11         \u001b[0;94m 6.778e-03\u001b[0m             2.275e-02         10.5s                                                \n",
      "   12         \u001b[0;94m 6.571e-03\u001b[0m             2.312e-02         10.6s                                                \n",
      "   13         \u001b[0;94m 6.466e-03\u001b[0m             2.348e-02         10.5s                                                \n",
      "   14         \u001b[0;94m 6.414e-03\u001b[0m             2.367e-02         10.6s                                                \n",
      "   15         \u001b[0;94m 6.385e-03\u001b[0m             2.386e-02         10.5s                                                \n",
      "   16         \u001b[0;94m 6.369e-03\u001b[0m             2.408e-02         10.5s                                                \n",
      "   17         \u001b[0;94m 6.363e-03\u001b[0m             2.422e-02         10.5s                                                \n",
      "\n",
      "Early termination condition fired at 17 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m256 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m32  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 2.302e-01\u001b[0m            \u001b[0;32m 1.399e-01\u001b[0m         21.3s                                     \n",
      "    2         \u001b[0;94m 1.262e-01\u001b[0m            \u001b[0;32m 7.723e-02\u001b[0m         20.4s                                     \n",
      "    3         \u001b[0;94m 7.029e-02\u001b[0m            \u001b[0;32m 4.616e-02\u001b[0m         20.6s                                     \n",
      "    4         \u001b[0;94m 4.048e-02\u001b[0m            \u001b[0;32m 3.140e-02\u001b[0m         20.7s                                     \n",
      "    5         \u001b[0;94m 2.457e-02\u001b[0m            \u001b[0;32m 2.476e-02\u001b[0m         20.7s                                     \n",
      "    6         \u001b[0;94m 1.608e-02\u001b[0m            \u001b[0;32m 2.208e-02\u001b[0m         20.5s                                     \n",
      "    7         \u001b[0;94m 1.154e-02\u001b[0m            \u001b[0;32m 2.133e-02\u001b[0m         20.4s                                     \n",
      "    8         \u001b[0;94m 9.115e-03\u001b[0m             2.148e-02         21.3s                                                \n",
      "    9         \u001b[0;94m 7.825e-03\u001b[0m             2.183e-02         19.8s                                                \n",
      "   10         \u001b[0;94m 7.141e-03\u001b[0m             2.236e-02         20.0s                                                \n",
      "   11         \u001b[0;94m 6.773e-03\u001b[0m             2.281e-02         20.5s                                                \n",
      "   12         \u001b[0;94m 6.578e-03\u001b[0m             2.316e-02         20.3s                                                \n",
      "   13         \u001b[0;94m 6.471e-03\u001b[0m             2.343e-02         20.2s                                                \n",
      "   14         \u001b[0;94m 6.415e-03\u001b[0m             2.374e-02         20.7s                                                \n",
      "   15         \u001b[0;94m 6.386e-03\u001b[0m             2.393e-02         21.3s                                                \n",
      "   16         \u001b[0;94m 6.372e-03\u001b[0m             2.409e-02         20.4s                                                \n",
      "   17         \u001b[0;94m 6.359e-03\u001b[0m             2.413e-02         21.1s                                                \n",
      "\n",
      "Early termination condition fired at 17 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m128 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m64  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 1.951e-01\u001b[0m            \u001b[0;32m 8.586e-02\u001b[0m         12.1s                                     \n",
      "    2         \u001b[0;94m 6.224e-02\u001b[0m            \u001b[0;32m 3.330e-02\u001b[0m         11.7s                                     \n",
      "    3         \u001b[0;94m 2.241e-02\u001b[0m            \u001b[0;32m 2.228e-02\u001b[0m         11.9s                                     \n",
      "    4         \u001b[0;94m 1.095e-02\u001b[0m            \u001b[0;32m 2.147e-02\u001b[0m         11.6s                                     \n",
      "    5         \u001b[0;94m 7.730e-03\u001b[0m             2.225e-02         11.6s                                                \n",
      "    6         \u001b[0;94m 6.815e-03\u001b[0m             2.311e-02         12.4s                                                \n",
      "    7         \u001b[0;94m 6.533e-03\u001b[0m             2.373e-02         12.0s                                                \n",
      "    8         \u001b[0;94m 6.439e-03\u001b[0m             2.410e-02         11.8s                                                \n",
      "    9         \u001b[0;94m 6.417e-03\u001b[0m             2.428e-02         11.8s                                                \n",
      "   10         \u001b[0;94m 6.407e-03\u001b[0m             2.421e-02         11.8s                                                \n",
      "   11         \u001b[0;94m 6.407e-03\u001b[0m             2.450e-02         11.8s                                                \n",
      "   12         \u001b[0;94m 6.410e-03\u001b[0m             2.445e-02         11.7s                                                \n",
      "   13         \u001b[0;94m 6.399e-03\u001b[0m             2.441e-02         12.6s                                                \n",
      "   14          6.411e-03             2.421e-02         12.0s                                                           \n",
      "\n",
      "Early termination condition fired at 14 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m256 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m64  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1         \u001b[0;94m 1.881e-01\u001b[0m            \u001b[0;32m 8.183e-02\u001b[0m         21.4s                                     \n",
      "    2         \u001b[0;94m 5.945e-02\u001b[0m            \u001b[0;32m 3.282e-02\u001b[0m         21.6s                                     \n",
      "    3         \u001b[0;94m 2.175e-02\u001b[0m            \u001b[0;32m 2.229e-02\u001b[0m         21.3s                                     \n",
      "    4         \u001b[0;94m 1.083e-02\u001b[0m            \u001b[0;32m 2.123e-02\u001b[0m         21.3s                                     \n",
      "    5         \u001b[0;94m 7.685e-03\u001b[0m             2.243e-02         21.3s                                                \n",
      "    6         \u001b[0;94m 6.818e-03\u001b[0m             2.313e-02         21.5s                                                \n",
      "    7         \u001b[0;94m 6.537e-03\u001b[0m             2.363e-02         21.8s                                                \n",
      "    8         \u001b[0;94m 6.447e-03\u001b[0m             2.401e-02         22.3s                                                \n",
      "    9         \u001b[0;94m 6.419e-03\u001b[0m             2.412e-02         21.7s                                                \n",
      "   10         \u001b[0;94m 6.406e-03\u001b[0m             2.433e-02         22.8s                                                \n",
      "   11         \u001b[0;94m 6.410e-03\u001b[0m             2.442e-02         21.2s                                                \n",
      "   12         \u001b[0;94m 6.404e-03\u001b[0m             2.458e-02         22.3s                                                \n",
      "   13          6.411e-03             2.457e-02         22.0s                                                           \n",
      "   14         \u001b[0;94m 6.407e-03\u001b[0m             2.462e-02         22.4s                                                \n",
      "\n",
      "Early termination condition fired at 14 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m512 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m64  \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 1.878e-01\u001b[0m            \u001b[0;32m 8.098e-02\u001b[0m         39.9s                                     \n",
      "    2         \u001b[0;94m 5.884e-02\u001b[0m            \u001b[0;32m 3.223e-02\u001b[0m         39.9s                                     \n",
      "    3         \u001b[0;94m 2.146e-02\u001b[0m            \u001b[0;32m 2.211e-02\u001b[0m         39.7s                                     \n",
      "    4         \u001b[0;94m 1.069e-02\u001b[0m            \u001b[0;32m 2.134e-02\u001b[0m         40.1s                                     \n",
      "    5         \u001b[0;94m 7.634e-03\u001b[0m             2.223e-02         39.6s                                                \n",
      "    6         \u001b[0;94m 6.764e-03\u001b[0m             2.295e-02         40.7s                                                \n",
      "    7         \u001b[0;94m 6.504e-03\u001b[0m             2.368e-02         38.7s                                                \n",
      "    8         \u001b[0;94m 6.441e-03\u001b[0m             2.391e-02         39.6s                                                \n",
      "    9         \u001b[0;94m 6.422e-03\u001b[0m             2.409e-02         39.9s                                                \n",
      "   10         \u001b[0;94m 6.406e-03\u001b[0m             2.427e-02         40.2s                                                \n",
      "   11         \u001b[0;94m 6.376e-03\u001b[0m             2.457e-02         40.0s                                                \n",
      "   12          6.412e-03             2.436e-02         41.5s                                                           \n",
      "   13          6.396e-03             2.470e-02         41.5s                                                           \n",
      "   14          6.409e-03             2.440e-02         40.7s                                                           \n",
      "\n",
      "Early termination condition fired at 14 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m256 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m128 \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 1.401e-01\u001b[0m            \u001b[0;32m 3.712e-02\u001b[0m         25.3s                                     \n",
      "    2         \u001b[0;94m 1.836e-02\u001b[0m            \u001b[0;32m 2.141e-02\u001b[0m         25.4s                                     \n",
      "    3         \u001b[0;94m 7.369e-03\u001b[0m             2.242e-02         24.9s                                                \n",
      "    4         \u001b[0;94m 6.573e-03\u001b[0m             2.363e-02         26.1s                                                \n",
      "    5         \u001b[0;94m 6.509e-03\u001b[0m             2.338e-02         24.4s                                                \n",
      "    6          6.533e-03             2.377e-02         24.2s                                                           \n",
      "    7         \u001b[0;94m 6.506e-03\u001b[0m             2.379e-02         24.1s                                                \n",
      "    8          6.518e-03             2.433e-02         24.2s                                                           \n",
      "    9         \u001b[0;94m 6.511e-03\u001b[0m             2.448e-02         25.3s                                                \n",
      "   10         \u001b[0;94m 6.501e-03\u001b[0m             2.455e-02         25.5s                                                \n",
      "   11         \u001b[0;94m 6.492e-03\u001b[0m             2.353e-02         25.4s                                                \n",
      "   12          6.504e-03             2.333e-02         25.6s                                                           \n",
      "\n",
      "Early termination condition fired at 12 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m512 \u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m128 \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 1.345e-01\u001b[0m            \u001b[0;32m 3.408e-02\u001b[0m         43.5s                                     \n",
      "    2         \u001b[0;94m 1.733e-02\u001b[0m            \u001b[0;32m 2.053e-02\u001b[0m         43.7s                                     \n",
      "    3         \u001b[0;94m 7.361e-03\u001b[0m             2.297e-02         42.8s                                                \n",
      "    4         \u001b[0;94m 6.662e-03\u001b[0m             2.349e-02         42.6s                                                \n",
      "    5         \u001b[0;94m 6.499e-03\u001b[0m             2.362e-02         41.3s                                                \n",
      "    6         \u001b[0;94m 6.504e-03\u001b[0m             2.338e-02         41.6s                                                \n",
      "    7          6.533e-03             2.394e-02         42.4s                                                           \n",
      "    8          6.516e-03             2.434e-02         42.1s                                                           \n",
      "    9          6.525e-03             2.453e-02         42.8s                                                           \n",
      "   10          6.517e-03             2.475e-02         42.8s                                                           \n",
      "   11         \u001b[0;94m 6.492e-03\u001b[0m             2.455e-02         43.5s                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12          6.503e-03             2.409e-02         42.9s                                                           \n",
      "\n",
      "Early termination condition fired at 12 iterations.\n",
      "Residual sum of squares: 0.02\n",
      "Variance score: 1.00\n",
      "Initializing neural network with 3 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m1024\u001b[0m\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m128 \u001b[0m\n",
      "  - Dense: \u001b[1;97mLinear    \u001b[0m Units:  \u001b[1;97m65536\u001b[0m\n",
      "\n",
      "Training on dataset of 31 samples with 6,094,848 total size.\n",
      "  - Train: 31         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 1.336e-01\u001b[0m            \u001b[0;32m 3.389e-02\u001b[0m         79.2s                                     \n",
      "    2         \u001b[0;94m 1.739e-02\u001b[0m            \u001b[0;32m 2.133e-02\u001b[0m         78.8s                                     \n",
      "    3         \u001b[0;94m 7.405e-03\u001b[0m             2.298e-02         81.6s                                                \n",
      "...."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "            format=\"%(message)s\",\n",
    "            level=logging.DEBUG,\n",
    "            stream=sys.stdout)    \n",
    "\n",
    "hunit_sen_filename = os.path.join(main_folder, '20180121_P1092977057_nn','hunit_sensitivity.csv')\n",
    "\n",
    "#for lr in learning_rates:\n",
    "for hidden_units in all_hidden_units:\n",
    "    \n",
    "    hunit_config = '_'.join([str(n) for n in hidden_units])\n",
    "    \n",
    "    errors = []\n",
    "    def store_stats(avg_valid_error, avg_train_error, **_):\n",
    "        errors.append((avg_valid_error, avg_train_error))\n",
    "    \n",
    "    layers = create_layers(hidden_units, dropouts, normalizes, activation, output_dim)\n",
    "    \n",
    "    nn = Regressor(\n",
    "            layers = layers,\n",
    "            learning_rate=learning_rate,\n",
    "            learning_rule='adadelta',\n",
    "            batch_size = batch_size,\n",
    "            #valid_size = 0.25,\n",
    "            valid_set = valid_set,\n",
    "            loss_type=loss_type,\n",
    "            n_iter=n_iter,\n",
    "            verbose=True,\n",
    "            callback={'on_epoch_finish': store_stats})\n",
    "    try:\n",
    "        nn.fit(dataset.train_yz, dataset.train_x)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    filename = os.path.join(main_folder, '20180121_P1092977057_nn','error_log_hunits%s.csv' % hunit_config)\n",
    "    write_log_error(filename, errors)\n",
    "    \n",
    "    pickle_filename = os.path.join(main_folder, '20180121_P1092977057_nn', 'nn_hunits%s.pkl' % hunit_config)\n",
    "    pickle.dump(nn, open(pickle_filename, 'wb'))\n",
    "    \n",
    "    prediction = nn.predict(dataset.valid_yz)\n",
    "    rss = np.mean((prediction - dataset.valid_x) ** 2)\n",
    "    var_score = nn.score(dataset.valid_yz, prediction)\n",
    "    \n",
    "    mad, max_ad, min_ad = mean_absolute_error(dataset, dataset.valid_yz, dataset.valid_x, prediction)\n",
    "    \n",
    "    print(\"Residual sum of squares: %.2f\"% rss)\n",
    "    print('Variance score: %.2f' %  var_score) # Explained variance score: 1 is perfect prediction\n",
    "    \n",
    "    with open(hunit_sen_filename, \"a\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow((hunit_config, mad, max_ad, min_ad, rss, var_score))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.4)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAEWCAYAAABhUT6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7M3MzEqck72ZmVmJc7I3MzMrcf8fTJs9f3YKB3YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x263005c2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# learning rate sensitivity\n",
    "def read_learning_rate_sensitivity_file(filename):\n",
    "\n",
    "    sensitivity = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            if not row: continue\n",
    "            sensitivity.append(np.asarray(row, dtype=np.float32))\n",
    "    return np.asarray(sensitivity)\n",
    "\n",
    "lr_sen_filename = os.path.join(main_folder, '20180121_P1092977057_nn','lr_sensitivity.csv')\n",
    "sensitivity = read_learning_rate_sensitivity_file(lr_sen_filename)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(np.log10(sensitivity[:, 0]), sensitivity[:, 1])\n",
    "ax1.set_title('Sensitivity of Learning rate of Adadelta')\n",
    "ax1.set_xlabel('Learning rate')\n",
    "ax1.set_ylabel('Residual sum of squares')\n",
    "ax1.set_ylim(0, 0.4)\n",
    "#ax1.set_xlim(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 0.02\n",
      "Variance score: 0.00\n"
     ]
    }
   ],
   "source": [
    "lr_sen_filename = os.path.join(main_folder, 'lr_sensitivity.csv')\n",
    "rss = np.mean((nn.predict(dataset.valid_yz) - dataset.valid_x) ** 2)\n",
    "var_score = nn.score(dataset.valid_yz, dataset.valid_x)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"% rss)\n",
    "print('Variance score: %.2f' %  var_score) # Explained variance score: 1 is perfect prediction\n",
    "\n",
    "with open(lr_sen_filename, \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow((rss, var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/D/dev/data/20171205_cirrus_manual_results\\\\20180121_P1092977057_nn\\\\lr_sensitivity.csv'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(main_folder, '20180121_P1092977057_nn','lr_sensitivity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "            format=\"%(message)s\",\n",
    "            level=logging.DEBUG,\n",
    "            stream=sys.stdout)\n",
    "\n",
    "#layers = [ Native(lasagne.DenseLayer, num_units= 16, nonlinearity=nl.leaky_rectify),\n",
    "#           Layer(\"Linear\")]\n",
    "layers = [ Layer(\"Tanh\", units= 16),\n",
    "           Layer(\"Linear\", units= output_dim)]\n",
    "\n",
    "nn = Regressor(\n",
    "    layers = layers,\n",
    "    #learning_rate=0.02,\n",
    "    learning_rule='adadelta',\n",
    "    batch_size = batch_size,\n",
    "    #valid_size = 0.25,\n",
    "    valid_set = (dataset.valid_yz, dataset.valid_x),\n",
    "    loss_type=loss_type,\n",
    "    n_iter=n_iter,\n",
    "    verbose=True)\n",
    "# normalize = ['batch', 'weights']\n",
    "# regularize = [None, 'dropout'] --> dropout_rate = [0.1, 0.2, 0.3, 0.4, 0.5, 0.7]\n",
    "#pickle.dump(nn, open('nn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'loss_type':['mse', 'mae'],\n",
    "              'hidden0_units': [16, 32, 64, 128, 256, 512, 1024],\n",
    "              'hidden0_dropout': [None, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "              'hidden0_normalize': [None, 'batch', 'weights']}\n",
    "gs = GridSearchCV(nn, param_grid=param_grid, iid=False, n_jobs=1, verbose=100,\n",
    "                  scoring='neg_mean_squared_error', return_train_score =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing neural network with 2 layers, 131072 inputs and 65536 outputs.\n",
      "  - Dense: Rectifier  Units:  16  \n",
      "  - Dense: Linear     Units:  65536\n",
      "\n",
      "Training on dataset of 10 samples with 1,966,080 total size.\n",
      "  - Train: 10         Valid: 1   \n",
      "  - Terminating loop after 500 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         ..............................................                                                            3.488e-01             2.520e-01          1.1s\n",
      "    2         ..............................................                                                            3.486e-01             2.519e-01          1.1s\n",
      "    3         ..............................................                                                            3.486e-01             2.518e-01          1.1s\n",
      "    4         ..............................................                                                            3.485e-01             2.518e-01          1.1s\n",
      "    5         ..............................................                                                            3.485e-01             2.518e-01          1.1s\n",
      "    6         ..............................................                                                            3.485e-01             2.518e-01          1.1s\n",
      "    7         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "    8         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "    9         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   10         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   11         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   12         ..............................................                                                            3.485e-01             2.518e-01          1.1s\n",
      "   13         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   14         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   15         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   16         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   17         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   18         ..............................................                                                            3.485e-01             2.518e-01          1.0s\n",
      "   19         ..............................................                                                            3.484e-01             2.518e-01          1.0s\n",
      "   20         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   21         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   22         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   23         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   24         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   25         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   26         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   27         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   28         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   29         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   30         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   31         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   32         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   33         ..............................................                                                            3.484e-01             2.517e-01          1.0s\n",
      "   34         ..............................................                                                            3.483e-01             2.517e-01          1.0s\n",
      "   35         ..............................................                                                            3.483e-01             2.517e-01          1.0s\n",
      "   36         ..............................................                                                            3.483e-01             2.517e-01          1.0s\n",
      "   37         ..............................................                                                            3.483e-01             2.517e-01          1.0s\n",
      "   38         ..............................................                                                            3.483e-01             2.517e-01          1.0s\n",
      "   39         ..............................................                                                            3.483e-01             2.516e-01          1.0s\n",
      "   40         ..............................................                                                            3.483e-01             2.516e-01          1.0s\n",
      "   41         ..............................................                                                            3.483e-01             2.516e-01          1.0s\n",
      "   42         ..............................................                                                            3.483e-01             2.516e-01          1.0s\n",
      "   43         ..............................................                                                            3.483e-01             2.516e-01          1.0s\n",
      "   44         ..............................................                                                            3.482e-01             2.516e-01          1.0s\n",
      "   45         ..............................................                                                            3.482e-01             2.516e-01          1.0s\n",
      "   46         ..............................................                                                            3.482e-01             2.516e-01          1.0s\n",
      "   47         ..............................................                                                            3.482e-01             2.516e-01          1.0s\n",
      "   48         ..............................................                                                            3.482e-01             2.516e-01          1.1s\n",
      "   49         ..............................................                                                            3.482e-01             2.515e-01          1.1s\n",
      "   50         ..............................................                                                            3.481e-01             2.515e-01          1.2s\n",
      "   51         ..............................................                                                            3.481e-01             2.515e-01          1.2s\n",
      "   52         ..............................................                                                            3.481e-01             2.515e-01          1.4s\n",
      "   53         ..............................................                                                            3.481e-01             2.515e-01          1.1s\n",
      "   54         ..............................................                                                            3.480e-01             2.515e-01          1.1s\n",
      "   55         ..............................................                                                            3.480e-01             2.514e-01          1.1s\n",
      "   56         ..............................................                                                            3.480e-01             2.514e-01          1.0s\n",
      "   57         ..............................................                                                            3.480e-01             2.514e-01          1.1s\n",
      "   58         ..............................................                                                            3.479e-01             2.514e-01          1.1s\n",
      "   59         ..............................................                                                            3.479e-01             2.514e-01          1.1s\n",
      "   60         ..............................................                                                            3.479e-01             2.513e-01          1.1s\n",
      "   61         ..............................................                                                            3.478e-01             2.513e-01          1.0s\n",
      "   62         ..............................................                                                            3.478e-01             2.513e-01          1.1s\n",
      "   63         ..............................................                                                            3.478e-01             2.513e-01          1.2s\n",
      "   64         ..............................................                                                            3.477e-01             2.512e-01          1.0s\n",
      "   65         ..............................................                                                            3.477e-01             2.512e-01          1.0s\n",
      "   66         ..............................................                                                            3.476e-01             2.512e-01          1.0s\n",
      "   67         ..............................................                                                            3.476e-01             2.511e-01          1.2s\n",
      "   68         ..............................................                                                            3.475e-01             2.511e-01          1.1s\n",
      "   69         ..............................................                                                            3.475e-01             2.510e-01          1.0s\n",
      "   70         ..............................................                                                            3.474e-01             2.510e-01          1.0s\n",
      "   71         ..............................................                                                            3.473e-01             2.510e-01          1.0s\n",
      "   72         ..............................................                                                            3.473e-01             2.509e-01          1.2s\n",
      "   73         ..............................................                                                            3.472e-01             2.509e-01          1.1s\n",
      "   74         ..............................................                                                            3.471e-01             2.508e-01          1.3s\n",
      "   75         ..............................................                                                            3.470e-01             2.507e-01          1.2s\n",
      "   76         ..............................................                                                            3.469e-01             2.507e-01          1.2s\n",
      "   77         ..............................................                                                            3.469e-01             2.506e-01          1.2s\n",
      "   78         ..............................................                                                            3.468e-01             2.506e-01          1.2s\n",
      "   79         ..............................................                                                            3.467e-01             2.505e-01          1.2s\n",
      "   80         ..............................................                                                            3.465e-01             2.504e-01          1.1s\n",
      "   81         ..............................................                                                            3.464e-01             2.503e-01          1.1s\n",
      "   82         ..............................................                                                            3.463e-01             2.502e-01          1.2s\n",
      "   83         ..............................................                                                            3.462e-01             2.501e-01          1.2s\n",
      "   84         ..............................................                                                            3.460e-01             2.501e-01          1.3s\n",
      "   85         ..............................................                                                            3.459e-01             2.499e-01          1.1s\n",
      "   86         ..............................................                                                            3.457e-01             2.498e-01          1.2s\n",
      "   87         ..............................................                                                            3.456e-01             2.497e-01          1.2s\n",
      "   88         ..............................................                                                            3.454e-01             2.496e-01          1.2s\n",
      "   89         ..............................................                                                            3.452e-01             2.495e-01          1.2s\n",
      "   90         ..............................................                                                            3.450e-01             2.493e-01          1.1s\n",
      "   91         ..............................................                                                            3.448e-01             2.492e-01          1.1s\n",
      "   92         ..............................................                                                            3.446e-01             2.490e-01          1.1s\n",
      "   93         ..............................................                                                            3.443e-01             2.489e-01          1.1s\n",
      "   94         ..............................................                                                            3.441e-01             2.487e-01          1.0s\n",
      "   95         ..............................................                                                            3.438e-01             2.485e-01          1.2s\n",
      "   96         ..............................................                                                            3.435e-01             2.483e-01          1.3s\n",
      "   97         ..............................................                                                            3.432e-01             2.481e-01          1.1s\n",
      "   98         ..............................................                                                            3.429e-01             2.479e-01          1.1s\n",
      "   99         ..............................................                                                            3.426e-01             2.476e-01          1.1s\n",
      "  100         ..............................................                                                            3.422e-01             2.474e-01          1.1s\n",
      "  101         ..............................................                                                            3.418e-01             2.471e-01          1.0s\n",
      "  102         ..............................................                                                            3.414e-01             2.468e-01          0.9s\n",
      "  103         ..............................................                                                            3.410e-01             2.465e-01          1.1s\n",
      "  104         ..............................................                                                            3.405e-01             2.462e-01          1.3s\n",
      "  105         ..............................................                                                            3.400e-01             2.459e-01          1.3s\n",
      "  106         ..............................................                                                            3.395e-01             2.455e-01          1.1s\n",
      "  107         ..............................................                                                            3.390e-01             2.452e-01          0.9s\n",
      "  108         ..............................................                                                            3.384e-01             2.448e-01          1.0s\n",
      "  109         ..............................................                                                            3.378e-01             2.444e-01          1.1s\n",
      "  110         ..............................................                                                            3.372e-01             2.439e-01          0.9s\n",
      "  111         ..............................................                                                            3.365e-01             2.434e-01          0.9s\n",
      "  112         ..............................................                                                            3.358e-01             2.429e-01          1.0s\n",
      "  113         ..............................................                                                            3.350e-01             2.424e-01          1.0s\n",
      "  114         ..............................................                                                            3.342e-01             2.419e-01          1.0s\n",
      "  115         ..............................................                                                            3.333e-01             2.413e-01          1.0s\n",
      "  116         ..............................................                                                            3.324e-01             2.407e-01          1.0s\n",
      "  117         ..............................................                                                            3.315e-01             2.400e-01          1.0s\n",
      "  118         ..............................................                                                            3.305e-01             2.393e-01          1.0s\n",
      "  119         ..............................................                                                            3.294e-01             2.386e-01          0.9s\n",
      "  120         ..............................................                                                            3.283e-01             2.378e-01          0.8s\n",
      "  121         ..............................................                                                            3.271e-01             2.370e-01          0.9s\n",
      "  122         ..............................................                                                            3.258e-01             2.361e-01          1.0s\n",
      "  123         ..............................................                                                            3.245e-01             2.352e-01          0.9s\n",
      "  124         ..............................................                                                            3.231e-01             2.343e-01          1.1s\n",
      "  125         ..............................................                                                            3.216e-01             2.333e-01          0.9s\n",
      "  126         ..............................................                                                            3.201e-01             2.322e-01          1.0s\n",
      "  127         ..............................................                                                            3.185e-01             2.311e-01          1.0s\n",
      "  128         ..............................................                                                            3.167e-01             2.299e-01          1.0s\n",
      "  129         ..............................................                                                            3.149e-01             2.287e-01          0.9s\n",
      "  130         ..............................................                                                            3.131e-01             2.274e-01          0.9s\n",
      "  131         ..............................................                                                            3.111e-01             2.260e-01          0.9s\n",
      "  132         ..............................................                                                            3.090e-01             2.246e-01          0.9s\n",
      "  133         ..............................................                                                            3.068e-01             2.231e-01          0.9s\n",
      "  134         ..............................................                                                            3.045e-01             2.216e-01          0.9s\n",
      "  135         ..............................................                                                            3.021e-01             2.200e-01          0.9s\n",
      "  136         ..............................................                                                            2.996e-01             2.183e-01          0.9s\n",
      "  137         ..............................................                                                            2.970e-01             2.165e-01          0.9s\n",
      "  138         ..............................................                                                            2.943e-01             2.146e-01          0.9s\n",
      "  139         ..............................................                                                            2.914e-01             2.127e-01          0.9s\n",
      "  140         ..............................................                                                            2.884e-01             2.107e-01          0.9s\n",
      "  141         ..............................................                                                            2.853e-01             2.086e-01          0.9s\n",
      "  142         ..............................................                                                            2.821e-01             2.065e-01          0.9s\n",
      "  143         ..............................................                                                            2.788e-01             2.042e-01          1.0s\n",
      "  144         ..............................................                                                            2.753e-01             2.019e-01          0.9s\n",
      "  145         ..............................................                                                            2.717e-01             1.995e-01          1.0s\n",
      "  146         ..............................................                                                            2.680e-01             1.971e-01          1.0s\n",
      "  147         ..............................................                                                            2.642e-01             1.945e-01          0.9s\n",
      "  148         ..............................................                                                            2.603e-01             1.919e-01          0.9s\n",
      "  149         ..............................................                                                            2.562e-01             1.892e-01          0.9s\n",
      "  150         ..............................................                                                            2.520e-01             1.864e-01          0.9s\n",
      "  151         ..............................................                                                            2.477e-01             1.836e-01          0.9s\n",
      "  152         ..............................................                                                            2.433e-01             1.806e-01          0.9s\n",
      "  153         ..............................................                                                            2.387e-01             1.777e-01          0.9s\n",
      "  154         ..............................................                                                            2.341e-01             1.746e-01          0.9s\n",
      "  155         ..............................................                                                            2.294e-01             1.715e-01          0.9s\n",
      "  156         ..............................................                                                            2.246e-01             1.684e-01          0.9s\n",
      "  157         ..............................................                                                            2.197e-01             1.652e-01          0.9s\n",
      "  158         ..............................................                                                            2.147e-01             1.620e-01          0.9s\n",
      "  159         ..............................................                                                            2.097e-01             1.587e-01          0.9s\n",
      "  160         ..............................................                                                            2.046e-01             1.554e-01          0.9s\n",
      "  161         ..............................................                                                            1.995e-01             1.521e-01          0.9s\n",
      "  162         ..............................................                                                            1.943e-01             1.488e-01          0.9s\n",
      "  163         ..............................................                                                            1.890e-01             1.454e-01          0.9s\n",
      "  164         ..............................................                                                            1.838e-01             1.421e-01          0.9s\n",
      "  165         ..............................................                                                            1.785e-01             1.388e-01          0.9s\n",
      "  166         ..............................................                                                            1.733e-01             1.354e-01          1.0s\n",
      "  167         ..............................................                                                            1.680e-01             1.321e-01          0.9s\n",
      "  168         ..............................................                                                            1.628e-01             1.288e-01          0.9s\n",
      "  169         ..............................................                                                            1.576e-01             1.255e-01          0.9s\n",
      "  170         ..............................................                                                            1.524e-01             1.223e-01          0.9s\n",
      "  171         ..............................................                                                            1.473e-01             1.190e-01          0.9s\n",
      "  172         ..............................................                                                            1.422e-01             1.158e-01          0.9s\n",
      "  173         ..............................................                                                            1.372e-01             1.127e-01          0.9s\n",
      "  174         ..............................................                                                            1.322e-01             1.096e-01          0.9s\n",
      "  175         ..............................................                                                            1.274e-01             1.066e-01          0.9s\n",
      "  176         ..............................................                                                            1.226e-01             1.037e-01          0.9s\n",
      "  177         ..............................................                                                            1.179e-01             1.008e-01          0.9s\n",
      "  178         ..............................................                                                            1.133e-01             9.797e-02          0.9s\n",
      "  179         ..............................................                                                            1.088e-01             9.517e-02          0.9s\n",
      "  180         ..............................................                                                            1.045e-01             9.256e-02          0.9s\n",
      "  181         ..............................................                                                            1.002e-01             9.000e-02          0.9s\n",
      "  182         ..............................................                                                            9.605e-02             8.740e-02          0.9s\n",
      "  183         ..............................................                                                            9.202e-02             8.495e-02          0.9s\n",
      "  184         ..............................................                                                            8.811e-02             8.257e-02          0.9s\n",
      "  185         ..............................................                                                            8.432e-02             8.031e-02          0.9s\n",
      "  186         ..............................................                                                            8.066e-02             7.810e-02          1.0s\n",
      "  187         ..............................................                                                            7.713e-02             7.592e-02          0.9s\n",
      "  188         ..............................................                                                            7.371e-02             7.391e-02          0.9s\n",
      "  189         ..............................................                                                            7.042e-02             7.197e-02          0.9s\n",
      "  190         ..............................................                                                            6.726e-02             7.011e-02          0.9s\n",
      "  191         ..............................................                                                            6.421e-02             6.835e-02          0.9s\n",
      "  192         ..............................................                                                            6.129e-02             6.653e-02          0.9s\n",
      "  193         ..............................................                                                            5.849e-02             6.476e-02          0.9s\n",
      "  194         ..............................................                                                            5.580e-02             6.321e-02          0.9s\n",
      "  195         ..............................................                                                            5.323e-02             6.168e-02          0.9s\n",
      "  196         ..............................................                                                            5.077e-02             6.016e-02          0.9s\n",
      "  197         ..............................................                                                            4.842e-02             5.876e-02          0.9s\n",
      "  198         ..............................................                                                            4.618e-02             5.751e-02          0.9s\n",
      "  199         ..............................................                                                            4.404e-02             5.628e-02          0.9s\n",
      "  200         ..............................................                                                            4.199e-02             5.506e-02          0.9s\n",
      "  201         ..............................................                                                            4.005e-02             5.397e-02          0.9s\n",
      "  202         ..............................................                                                            3.820e-02             5.285e-02          0.9s\n",
      "  203         ..............................................                                                            3.643e-02             5.185e-02          0.9s\n",
      "  204         ..............................................                                                            3.476e-02             5.082e-02          0.9s\n",
      "  205         ..............................................                                                            3.317e-02             4.988e-02          0.9s\n",
      "  206         ..............................................                                                            3.165e-02             4.898e-02          0.9s\n",
      "  207         ..............................................                                                            3.022e-02             4.812e-02          0.9s\n",
      "  208         ..............................................                                                            2.886e-02             4.735e-02          0.9s\n",
      "  209         ..............................................                                                            2.757e-02             4.664e-02          0.9s\n",
      "  210         ..............................................                                                            2.634e-02             4.593e-02          0.9s\n",
      "  211         ..............................................                                                            2.518e-02             4.522e-02          0.9s\n",
      "  212         ..............................................                                                            2.408e-02             4.470e-02          0.9s\n",
      "  213         ..............................................                                                            2.305e-02             4.408e-02          0.9s\n",
      "  214         ..............................................                                                            2.206e-02             4.344e-02          0.9s\n",
      "  215         ..............................................                                                            2.113e-02             4.281e-02          0.9s\n",
      "  216         ..............................................                                                            2.025e-02             4.231e-02          0.9s\n",
      "  217         ..............................................                                                            1.942e-02             4.188e-02          0.9s\n",
      "  218         ..............................................                                                            1.864e-02             4.145e-02          0.9s\n",
      "  219         ..............................................                                                            1.789e-02             4.104e-02          0.9s\n",
      "  220         ..............................................                                                            1.719e-02             4.063e-02          0.9s\n",
      "  221         ..............................................                                                            1.653e-02             4.028e-02          0.9s\n",
      "  222         ..............................................                                                            1.590e-02             3.987e-02          0.9s\n",
      "  223         ..............................................                                                            1.531e-02             3.952e-02          0.9s\n",
      "  224         ..............................................                                                            1.476e-02             3.922e-02          0.9s\n",
      "  225         ..............................................                                                            1.423e-02             3.895e-02          0.9s\n",
      "  226         ..............................................                                                            1.374e-02             3.869e-02          0.9s\n",
      "  227         ..............................................                                                            1.326e-02             3.851e-02          0.9s\n",
      "  228         ..............................................                                                            1.283e-02             3.819e-02          0.9s\n",
      "  229         ..............................................                                                            1.241e-02             3.793e-02          0.9s\n",
      "  230         ..............................................                                                            1.202e-02             3.769e-02          0.9s\n",
      "  231         ..............................................                                                            1.165e-02             3.747e-02          0.9s\n",
      "  232         ..............................................                                                            1.130e-02             3.729e-02          0.9s\n",
      "  233         ..............................................                                                            1.097e-02             3.705e-02          0.9s\n",
      "  234         ..............................................                                                            1.066e-02             3.692e-02          0.9s\n",
      "  235         ..............................................                                                            1.037e-02             3.672e-02          0.9s\n",
      "  236         ..............................................                                                            1.010e-02             3.658e-02          0.9s\n",
      "  237         ..............................................                                                            9.840e-03             3.646e-02          0.9s\n",
      "  238         ..............................................                                                            9.597e-03             3.630e-02          0.9s\n",
      "  239         ..............................................                                                            9.367e-03             3.609e-02          0.9s\n",
      "  240         ..............................................                                                            9.152e-03             3.595e-02          0.9s\n",
      "  241         ..............................................                                                            8.948e-03             3.590e-02          0.9s\n",
      "  242         ..............................................                                                            8.757e-03             3.572e-02          0.9s\n",
      "  243         ..............................................                                                            8.576e-03             3.568e-02          0.9s\n",
      "  244         ..............................................                                                            8.408e-03             3.554e-02          0.9s\n",
      "  245         ..............................................                                                            8.248e-03             3.545e-02          0.9s\n",
      "  246         ..............................................                                                            8.095e-03             3.530e-02          0.9s\n",
      "  247         ..............................................                                                            7.955e-03             3.517e-02          0.9s\n",
      "  248         ..............................................                                                            7.822e-03             3.510e-02          0.9s\n",
      "  249         ..............................................                                                            7.697e-03             3.500e-02          0.9s\n",
      "  250         ..............................................                                                            7.579e-03             3.495e-02          0.9s\n",
      "  251         ..............................................                                                            7.468e-03             3.490e-02          0.9s\n",
      "  252         ..............................................                                                            7.364e-03             3.484e-02          0.9s\n",
      "  253         ..............................................                                                            7.263e-03             3.489e-02          0.9s\n",
      "  254         ..............................................                                                            7.172e-03             3.481e-02          0.9s\n",
      "  255         ..............................................                                                            7.085e-03             3.478e-02          0.9s\n",
      "  256         ..............................................                                                            7.003e-03             3.475e-02          0.9s\n",
      "  257         ..............................................                                                            6.924e-03             3.479e-02          0.9s\n",
      "  258         ..............................................                                                            6.852e-03             3.466e-02          0.9s\n",
      "  259         ..............................................                                                            6.782e-03             3.452e-02          0.9s\n",
      "  260         ..............................................                                                            6.718e-03             3.442e-02          0.9s\n",
      "  261         ..............................................                                                            6.661e-03             3.440e-02          0.9s\n",
      "  262         ..............................................                                                            6.600e-03             3.430e-02          0.9s\n",
      "  263         ..............................................                                                            6.549e-03             3.426e-02          0.9s\n",
      "  264         ..............................................                                                            6.498e-03             3.437e-02          0.9s\n",
      "  265         ..............................................                                                            6.452e-03             3.437e-02          0.9s\n",
      "  266         ..............................................                                                            6.408e-03             3.440e-02          0.9s\n",
      "  267         ..............................................                                                            6.365e-03             3.433e-02          0.9s\n",
      "  268         ..............................................                                                            6.326e-03             3.432e-02          0.9s\n",
      "  269         ..............................................                                                            6.289e-03             3.436e-02          0.9s\n",
      "  270         ..............................................                                                            6.254e-03             3.437e-02          0.9s\n",
      "  271         ..............................................                                                            6.222e-03             3.434e-02          0.9s\n",
      "  272         ..............................................                                                            6.190e-03             3.428e-02          0.9s\n",
      "  273         ..............................................                                                            6.161e-03             3.425e-02          0.9s\n",
      "  274         ..............................................                                                            6.134e-03             3.422e-02          0.9s\n",
      "  275         ..............................................                                                            6.108e-03             3.417e-02          0.9s\n",
      "  276         ..............................................                                                            6.084e-03             3.422e-02          0.9s\n",
      "  277         ..............................................                                                            6.061e-03             3.424e-02          0.9s\n",
      "  278         ..............................................                                                            6.038e-03             3.428e-02          0.9s\n",
      "  279         ..............................................                                                            6.019e-03             3.429e-02          0.9s\n",
      "  280         ..............................................                                                            6.000e-03             3.419e-02          0.9s\n",
      "  281         ..............................................                                                            5.983e-03             3.420e-02          0.9s\n",
      "  282         ..............................................                                                            5.966e-03             3.416e-02          0.9s\n",
      "  283         ..............................................                                                            5.951e-03             3.416e-02          0.9s\n",
      "  284         ..............................................                                                            5.936e-03             3.417e-02          0.9s\n",
      "  285         ..............................................                                                            5.922e-03             3.417e-02          0.9s\n",
      "  286         ..............................................                                                            5.906e-03             3.405e-02          0.9s\n",
      "  287         ..............................................                                                            5.896e-03             3.403e-02          0.9s\n",
      "  288         ..............................................                                                            5.885e-03             3.402e-02          0.9s\n",
      "  289         ..............................................                                                            5.873e-03             3.399e-02          0.9s\n",
      "  290         ..............................................                                                            5.863e-03             3.397e-02          0.9s\n",
      "  291         ..............................................                                                            5.854e-03             3.398e-02          0.9s\n",
      "  292         ..............................................                                                            5.845e-03             3.402e-02          0.9s\n",
      "  293         ..............................................                                                            5.836e-03             3.407e-02          0.9s\n",
      "  294         ..............................................                                                            5.828e-03             3.405e-02          0.9s\n",
      "  295         ..............................................                                                            5.820e-03             3.403e-02          0.9s\n",
      "  296         ..............................................                                                            5.811e-03             3.412e-02          0.9s\n",
      "  297         ..............................................                                                            5.804e-03             3.421e-02          0.9s\n",
      "  298         ..............................................                                                            5.801e-03             3.421e-02          0.9s\n",
      "  299         ..............................................                                                            5.792e-03             3.409e-02          1.0s\n",
      "  300         ..............................................                                                            5.789e-03             3.404e-02          0.9s\n",
      "  301         ..............................................                                                            5.784e-03             3.402e-02          0.9s\n",
      "\n",
      "Early termination condition fired at 301 iterations.\n"
     ]
    }
   ],
   "source": [
    "#gs.fit(X_train, y_train)\n",
    "try:\n",
    "    nn.fit(dataset.train_yz, dataset.train_x)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regressor(batch_size=1, callback=None, debug=False, dropout_rate=None,\n",
       "     f_stable=0.001,\n",
       "     hidden0=<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden0', units=16>,\n",
       "     layers=[<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden0', units=16>, <sknn.nn.Layer `Linear`: frozen=False, name='output', units=65536>],\n",
       "     learning_momentum=0.9, learning_rate=0.01, learning_rule='adadelta',\n",
       "     loss_type='mse', n_iter=500, n_stable=10, normalize=None,\n",
       "     output=<sknn.nn.Layer `Linear`: frozen=False, name='output', units=65536>,\n",
       "     parameters=None, random_state=None, regularize=None,\n",
       "     valid_set=(array([[ 0.,  0., ...,  1.,  1.]], dtype=float32), array([[ 0.77243,  0.76861, ...,  0.9145 ,  0.9182 ]], dtype=float32)),\n",
       "     valid_size=0.0, verbose=True, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 131072)\n",
      "Predict  [[ 0.83329676  0.82093655  0.82227153 ...,  0.58367749  0.55042307\n",
      "   0.56696111]]  target  [[ 0.77243137  0.76861286  0.7657361  ...,  0.90901375  0.9144969\n",
      "   0.9182024 ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_target_yz.shape)\n",
    "predict_x = nn.predict(scaled_target_yz)\n",
    "print('Predict ', predict_x, ' target ', scaled_target_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict  [[ 0.83329676  0.82093655  0.82227153 ...,  0.58367749  0.55042307\n",
      "   0.56696111]]  target  [[ 0.77243137  0.76861286  0.7657361  ...,  0.90901375  0.9144969\n",
      "   0.9182024 ]]\n"
     ]
    }
   ],
   "source": [
    "predict_x = nn.predict(dataset.valid_yz)\n",
    "print('Predict ', predict_x, ' target ', dataset.valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict  [[ 0.80821403  0.79714073  0.79811453 ...,  0.56630172  0.53427368\n",
      "   0.5499854 ]]  target  [[ 0.86423683  0.86062241  0.85721779 ...,  0.55589056  0.55522776\n",
      "   0.55510044]]\n"
     ]
    }
   ],
   "source": [
    "#print(dataset.train_x[0].reshape((-1, 65536)))\n",
    "predict_x = nn.predict(dataset.train_yz[0].reshape((-1, 131072)))\n",
    "print('Predict ', predict_x, ' target ', dataset.train_x[0].reshape((-1, 65536)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 0.03\n",
      "Variance score: 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((nn.predict(dataset.valid_yz) - dataset.valid_x) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % nn.score(dataset.valid_yz, dataset.valid_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best estimator ', gs.best_estimator_)\n",
    "print('Best params ', gs.best_params_)\n",
    "print('Best index ', gs.best_index_)\n",
    "print('Best score ', gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('score =', nn.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(nn, open('nn.pkl', 'wb'))\n",
    "#nn = pickle.load(open('nn.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_example = nn.predict(X_example)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
